# ğŸ–¼ï¸ Vision-LLM Image Question Answering System

An interactive **multimodal AI web application** that allows users to upload an image and ask natural-language questions about it.  
The system integrates **computer vision models** with **large language models (LLMs)** to analyze visual content and generate meaningful, human-like responses.

---

## ğŸ“¸ Demo Screenshot

Below is an example of the application in action:

![Vision-LLM Image QA Demo](assets/demo.png)

![Vision-LLM Image QA Demo](assets/Demo_Video.mp4)
---

## ğŸš€ Project Overview

This project demonstrates how **visual understanding** and **language reasoning** can be combined into a single intelligent system.  
Users upload an image, ask a question, and receive an AI-generated response based on deep visual analysis and contextual reasoning.

The entire system is implemented as a **web application** using Streamlit, making it interactive, user-friendly, and easy to run locally.

---

## âœ¨ Key Features

- ğŸ“¤ Upload images in **JPG / JPEG / PNG** format  
- ğŸ§  Automatic image understanding using deep learning  
- ğŸ—¨ï¸ Ask **natural-language questions** about the image  
- ğŸ” Object detection and image captioning  
- ğŸ¤– Reasoned responses generated by an LLM-powered agent  
- ğŸ¨ Custom-styled, clean user interface  
- ğŸ” Secure API key handling using environment variables  

---

## ğŸ§  System Architecture

The application follows a **modular and layered architecture**:

### 1ï¸âƒ£ Image Processing Layer
- Image captioning using **BLIP**
- Object detection using **DETR**
- Safe temporary image handling (Windows-compatible)

### 2ï¸âƒ£ Reasoning Layer
- Custom tools exposed to a **LangChain conversational agent**
- Multi-turn conversational memory
- LLM-based reasoning over visual observations

### 3ï¸âƒ£ Application Layer
- Interactive UI built with **Streamlit**
- Custom HTML/CSS styling
- Input validation and response rendering

---

## ğŸ› ï¸ Technologies Used

- **Python 3.10**
- **Streamlit** â€“ Web application framework
- **LangChain** â€“ Agent and tool orchestration
- **OpenAI GPT-3.5-Turbo** â€“ Language reasoning
- **Hugging Face Transformers**
  - BLIP (Image Captioning)
  - DETR (Object Detection)
- **PyTorch**
- **Pillow (PIL)** â€“ Image processing
- **HTML / CSS** â€“ UI customization

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/vision-llm-image-qa.git
cd vision-llm-image-qa

ğŸ§ª How to Use

Upload an image (JPG / JPEG / PNG).

Preview the uploaded image in the interface.

Enter a natural-language question such as:

â€œWhat objects are in the image?â€

â€œDescribe the image.â€

Receive an AI-generated answer based on visual understanding and reasoning.

ğŸ§© Project Structure
vision-llm-image-qa/
â”‚
â”œâ”€â”€ app.py              # Main Streamlit application
â”œâ”€â”€ tools.py            # LangChain custom tools
â”œâ”€â”€ vision_utils.py     # Computer vision utilities
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ assets/             # Images and screenshots
â”œâ”€â”€ notebooks/          # Experiments and tests
â””â”€â”€ README.md

ğŸ§  Skills Demonstrated

Multimodal AI system design

Computer vision model integration

LLM-based reasoning with LangChain

Secure API key management using environment variables

Windows-specific debugging and file handling

Modular and maintainable Python architecture

Streamlit-based UI development

End-to-end AI application deployment

ğŸ”® Future Enhancements

Bounding-box visualization on images

Confidence scores for detected objects

Support for multiple image inputs

Video-based question answering

Cloud deployment (Docker / Hugging Face Spaces)

ğŸ‘¤ Author

Adnan Faisal

ğŸ“§ Email: ajfaisal1208023@gmail.com

ğŸ“„ License

This project is licensed under the MIT License.

â­ Final Note

This project was designed, implemented, debugged, and deployed end-to-end as a complete AI system, demonstrating practical skills in computer vision, large language models, and modern AI application development.

